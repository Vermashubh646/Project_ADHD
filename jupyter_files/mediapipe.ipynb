{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video capture (0 = default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "# Loop to capture frames\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read a frame\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Live Video', frame)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video capture (0 = default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Convert image to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Get Lip Landmarks\n",
    "            upper_lip = (int(face_landmarks.landmark[11].x * w), int(face_landmarks.landmark[11].y * h))\n",
    "            lower_lip = (int(face_landmarks.landmark[16].x * w), int(face_landmarks.landmark[16].y * h))\n",
    "            \n",
    "            # Calculate lip distance\n",
    "            lip_distance = calculate_distance(upper_lip, lower_lip)\n",
    "\n",
    "            # cv2.putText(frame, f\"{lip_distance}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # Detect lip biting (threshold ~3 pixels)\n",
    "            if lip_distance < 10:\n",
    "                cv2.putText(frame, \"Lip Biting Detected\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # Get Eye Center Landmarks\n",
    "            left_eye = (int(face_landmarks.landmark[468].x * w), int(face_landmarks.landmark[468].y * h))\n",
    "            right_eye = (int(face_landmarks.landmark[473].x * w), int(face_landmarks.landmark[473].y * h))\n",
    "\n",
    "            # Draw landmarks\n",
    "            cv2.circle(frame, upper_lip, 3, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, lower_lip, 3, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, left_eye, 3, (255, 0, 0), -1)\n",
    "            cv2.circle(frame, right_eye, 3, (255, 0, 0), -1)\n",
    "\n",
    "    # Show Frame\n",
    "    cv2.imshow(\"Lip & Eye Detection\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)\n",
    "\n",
    "# Store past eye positions to track movement\n",
    "eye_positions = deque(maxlen=5)  # Stores last 5 eye positions\n",
    "\n",
    "def calculate_distance(p1, p2):\n",
    "    \"\"\"Calculate Euclidean distance between two points\"\"\"\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    h, w, _ = frame.shape  # Get frame dimensions\n",
    "\n",
    "    # Convert frame to RGB for MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Get Eye Center Landmarks\n",
    "            left_eye = (int(face_landmarks.landmark[468].x * w), int(face_landmarks.landmark[468].y * h))\n",
    "            right_eye = (int(face_landmarks.landmark[473].x * w), int(face_landmarks.landmark[473].y * h))\n",
    "\n",
    "            # Calculate eye center (average of both eyes)\n",
    "            eye_center = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
    "\n",
    "            # Append new eye position to queue\n",
    "            eye_positions.append(eye_center)\n",
    "\n",
    "            # Check movement if we have enough frames\n",
    "            if len(eye_positions) == 5:\n",
    "                total_movement = sum(\n",
    "                    calculate_distance(eye_positions[i], eye_positions[i + 1]) for i in range(len(eye_positions) - 1)\n",
    "                )\n",
    "\n",
    "                # If movement is too high, classify as attention loss\n",
    "                if total_movement > 10:  # Adjust threshold as needed\n",
    "                    cv2.putText(frame, \" Attention Loss Detected!\", (50, 100),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # Draw landmarks for visualization (Optional)\n",
    "            cv2.circle(frame, left_eye, 3, (255, 0, 0), -1)\n",
    "            cv2.circle(frame, right_eye, 3, (255, 0, 0), -1)\n",
    "\n",
    "    # Display Frame\n",
    "    cv2.imshow(\"Eye Movement Detection\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.15454411506653 480 640 3\n"
     ]
    }
   ],
   "source": [
    "def rel_position_eye(eye_landmarks,iris_landmarks):\n",
    "    # gives value [0,1] independent of frame width, can check eye motion\n",
    "    eye_left = eye_landmarks[0]#left corner of eye\n",
    "    eye_right = eye_landmarks[1]#right corner of eye\n",
    "    eye_iris=iris_landmarks\n",
    "\n",
    "\n",
    "    eye_range = np.linalg.norm(np.array(eye_left) - np.array(eye_right))\n",
    "    iris_left_dist=np.linalg.norm(np.array(eye_left) - np.array(eye_iris))\n",
    "    return iris_left_dist/eye_range\n",
    "\n",
    "gaze_history = deque(maxlen=30)\n",
    "# Initialize video capture (0 = default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "start = time.time()\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Convert image to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            \n",
    "\n",
    "            left_eye = [(int(face_landmarks.landmark[33].x * w), int(face_landmarks.landmark[33].y * h)),  # Left corner\n",
    "                        (int(face_landmarks.landmark[133].x * w), int(face_landmarks.landmark[133].y * h))]  # Right corner\n",
    "            right_eye = [(int(face_landmarks.landmark[362].x * w), int(face_landmarks.landmark[362].y * h)),  \n",
    "                         (int(face_landmarks.landmark[263].x * w), int(face_landmarks.landmark[263].y * h))]\n",
    "            right_iris=[(int(face_landmarks.landmark[473].x * w), int(face_landmarks.landmark[473].y * h))]\n",
    "            left_iris=[(int(face_landmarks.landmark[468].x * w), int(face_landmarks.landmark[468].y * h))]\n",
    "\n",
    "            left_iris_pos= rel_position_eye(left_eye,left_iris)\n",
    "            right_iris_pos= rel_position_eye(right_eye,right_iris)\n",
    "\n",
    "\n",
    "            # Determine gaze direction\n",
    "            gaze_direction = \"Center\"  # Default\n",
    "            if left_iris_pos < 0.4 and right_iris_pos < 0.4:\n",
    "                gaze_direction = \"Looking Right\"\n",
    "            elif left_iris_pos > 0.60 and right_iris_pos > 0.60:\n",
    "                gaze_direction = \"Looking Left\"\n",
    "            elif face_landmarks.landmark[468].y  > face_landmarks.landmark[33].y *(1+0.02):  \n",
    "                gaze_direction = \"Looking Down\"\n",
    "\n",
    "            # Store last few gaze directions\n",
    "            gaze_history.append(gaze_direction)\n",
    "\n",
    "            # Check if user is looking away for too long\n",
    "            if gaze_history.count(\"Looking Right\") > 11 or gaze_history.count(\"Looking Left\") > 11:\n",
    "                cv2.putText(frame, \"Distraction Detected!\", (50, 100),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            elif gaze_history.count(\"Looking Down\") > 11:\n",
    "                cv2.putText(frame, \"Possible Sleepiness!\", (50, 150),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "            # Draw landmarks\n",
    "\n",
    "            for (x, y) in left_eye + right_eye + left_iris + right_iris:\n",
    "                cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 0), -1)\n",
    "\n",
    "            # Display gaze direction\n",
    "            cv2.putText(frame, f\"Gaze: {gaze_direction}\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "            # cv2.putText(frame, f\"{rel_position_eye(left_eye,left_iris)}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            # print(f\"left = {rel_position_eye(left_eye,left_iris)}\",\"\\t\",f\"right = {rel_position_eye(right_eye,right_iris)}\")\n",
    "\n",
    "    # Show Frame\n",
    "    cv2.imshow(\"Eye Detection\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "end=time.time()\n",
    "print(end-start,h,w,_)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque(['Center',\n",
       "       'Center',\n",
       "       'Center',\n",
       "       'Center',\n",
       "       'Center',\n",
       "       'Center',\n",
       "       'Center',\n",
       "       'Center',\n",
       "       'Center',\n",
       "       'Center'],\n",
       "      maxlen=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaze_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
